#!/usr/bin/env python3
"""
strip_rollback_manager.py - Stripæ“ä½œå›æ»šç®¡ç†å™¨

æä¾›Stripæ“ä½œçš„å¤‡ä»½ã€å›æ»šå’Œç‰ˆæœ¬ç®¡ç†åŠŸèƒ½ï¼Œç¡®ä¿å®‰å…¨çš„Stripéƒ¨ç½²ã€‚
"""

import json
import os
import shutil
import sys
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict


@dataclass
class StripOperation:
    """Stripæ“ä½œè®°å½•"""
    id: str
    timestamp: str
    binary_path: str
    backup_path: str
    strip_method: str
    original_size: int
    stripped_size: int
    original_checksum: str
    stripped_checksum: str
    success: bool
    functionality_verified: bool
    error_message: Optional[str] = None
    notes: Optional[str] = None


@dataclass
class BackupMetadata:
    """å¤‡ä»½æ–‡ä»¶å…ƒæ•°æ®"""
    backup_id: str
    created_at: str
    original_path: str
    backup_path: str
    file_size: int
    checksum: str
    strip_operation_id: Optional[str] = None


class StripRollbackManager:
    """Stripæ“ä½œå›æ»šç®¡ç†å™¨"""
    
    def __init__(self, work_dir: str = ".strip_rollback"):
        self.work_dir = Path(work_dir)
        self.work_dir.mkdir(exist_ok=True)
        
        # æ•°æ®æ–‡ä»¶
        self.operations_file = self.work_dir / "operations.json"
        self.backups_file = self.work_dir / "backups.json"
        
        # å¤‡ä»½ç›®å½•
        self.backup_dir = self.work_dir / "backups"
        self.backup_dir.mkdir(exist_ok=True)
        
        # åŠ è½½å†å²æ•°æ®
        self.operations: List[StripOperation] = self._load_operations()
        self.backups: List[BackupMetadata] = self._load_backups()
        
        print(f"ğŸ—‚ï¸  Stripå›æ»šç®¡ç†å™¨åˆå§‹åŒ–")
        print(f"   å·¥ä½œç›®å½•: {self.work_dir}")
        print(f"   å¤‡ä»½ç›®å½•: {self.backup_dir}")
        print(f"   å†å²æ“ä½œ: {len(self.operations)} æ¡")
        print(f"   å¤‡ä»½æ–‡ä»¶: {len(self.backups)} ä¸ª")
    
    def _load_operations(self) -> List[StripOperation]:
        """åŠ è½½æ“ä½œå†å²"""
        if self.operations_file.exists():
            try:
                with open(self.operations_file, 'r') as f:
                    data = json.load(f)
                return [StripOperation(**op) for op in data]
            except (json.JSONDecodeError, TypeError) as e:
                print(f"âš ï¸  åŠ è½½æ“ä½œå†å²å¤±è´¥: {e}")
                return []
        return []
    
    def _load_backups(self) -> List[BackupMetadata]:
        """åŠ è½½å¤‡ä»½å…ƒæ•°æ®"""
        if self.backups_file.exists():
            try:
                with open(self.backups_file, 'r') as f:
                    data = json.load(f)
                return [BackupMetadata(**backup) for backup in data]
            except (json.JSONDecodeError, TypeError) as e:
                print(f"âš ï¸  åŠ è½½å¤‡ä»½å…ƒæ•°æ®å¤±è´¥: {e}")
                return []
        return []
    
    def _save_operations(self):
        """ä¿å­˜æ“ä½œå†å²"""
        with open(self.operations_file, 'w') as f:
            json.dump([asdict(op) for op in self.operations], f, indent=2)
    
    def _save_backups(self):
        """ä¿å­˜å¤‡ä»½å…ƒæ•°æ®"""
        with open(self.backups_file, 'w') as f:
            json.dump([asdict(backup) for backup in self.backups], f, indent=2)
    
    def _calculate_checksum(self, filepath: Path) -> str:
        """è®¡ç®—æ–‡ä»¶SHA256æ ¡éªŒå’Œ"""
        with open(filepath, 'rb') as f:
            return hashlib.sha256(f.read()).hexdigest()
    
    def _generate_operation_id(self) -> str:
        """ç”Ÿæˆæ“ä½œID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"strip_{timestamp}_{len(self.operations):03d}"
    
    def _generate_backup_id(self) -> str:
        """ç”Ÿæˆå¤‡ä»½ID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"backup_{timestamp}_{len(self.backups):03d}"
    
    def create_backup(self, binary_path: Path, operation_id: Optional[str] = None) -> str:
        """åˆ›å»ºå¤‡ä»½æ–‡ä»¶"""
        print(f"ğŸ’¾ åˆ›å»ºå¤‡ä»½: {binary_path}")
        
        if not binary_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {binary_path}")
        
        # ç”Ÿæˆå¤‡ä»½IDå’Œè·¯å¾„
        backup_id = self._generate_backup_id()
        backup_filename = f"{backup_id}_{binary_path.name}"
        backup_path = self.backup_dir / backup_filename
        
        try:
            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(binary_path, backup_path)
            
            # åˆ›å»ºå¤‡ä»½å…ƒæ•°æ®
            backup_metadata = BackupMetadata(
                backup_id=backup_id,
                created_at=datetime.now().isoformat(),
                original_path=str(binary_path),
                backup_path=str(backup_path),
                file_size=binary_path.stat().st_size,
                checksum=self._calculate_checksum(binary_path),
                strip_operation_id=operation_id
            )
            
            self.backups.append(backup_metadata)
            self._save_backups()
            
            print(f"âœ… å¤‡ä»½åˆ›å»ºæˆåŠŸ: {backup_path}")
            print(f"   å¤‡ä»½ID: {backup_id}")
            print(f"   æ–‡ä»¶å¤§å°: {backup_metadata.file_size:,} bytes")
            
            return backup_id
            
        except Exception as e:
            print(f"âŒ å¤‡ä»½åˆ›å»ºå¤±è´¥: {e}")
            raise
    
    def prepare_strip_operation(self, binary_path: Path, strip_method: str, 
                              create_backup: bool = True) -> str:
        """å‡†å¤‡Stripæ“ä½œ"""
        print(f"ğŸš€ å‡†å¤‡Stripæ“ä½œ: {binary_path}")
        print(f"   Stripæ–¹æ³•: {strip_method}")
        print(f"   è‡ªåŠ¨å¤‡ä»½: {create_backup}")
        
        if not binary_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {binary_path}")
        
        # ç”Ÿæˆæ“ä½œID
        operation_id = self._generate_operation_id()
        
        # åˆ›å»ºå¤‡ä»½
        backup_id = None
        backup_path = ""
        if create_backup:
            backup_id = self.create_backup(binary_path, operation_id)
            backup_metadata = self._find_backup_by_id(backup_id)
            backup_path = backup_metadata.backup_path if backup_metadata else ""
        
        # è®°å½•æ“ä½œä¿¡æ¯
        operation = StripOperation(
            id=operation_id,
            timestamp=datetime.now().isoformat(),
            binary_path=str(binary_path),
            backup_path=backup_path,
            strip_method=strip_method,
            original_size=binary_path.stat().st_size,
            stripped_size=0,  # å¾…æ›´æ–°
            original_checksum=self._calculate_checksum(binary_path),
            stripped_checksum="",  # å¾…æ›´æ–°
            success=False,  # å¾…æ›´æ–°
            functionality_verified=False,  # å¾…æ›´æ–°
        )
        
        self.operations.append(operation)
        self._save_operations()
        
        print(f"âœ… Stripæ“ä½œå‡†å¤‡å®Œæˆ")
        print(f"   æ“ä½œID: {operation_id}")
        if backup_id:
            print(f"   å¤‡ä»½ID: {backup_id}")
        
        return operation_id
    
    def complete_strip_operation(self, operation_id: str, success: bool, 
                                functionality_verified: bool = False,
                                error_message: Optional[str] = None,
                                notes: Optional[str] = None):
        """å®ŒæˆStripæ“ä½œè®°å½•"""
        operation = self._find_operation_by_id(operation_id)
        if not operation:
            raise ValueError(f"æ“ä½œä¸å­˜åœ¨: {operation_id}")
        
        binary_path = Path(operation.binary_path)
        
        # æ›´æ–°æ“ä½œè®°å½•
        operation.success = success
        operation.functionality_verified = functionality_verified
        operation.error_message = error_message
        operation.notes = notes
        
        if binary_path.exists():
            operation.stripped_size = binary_path.stat().st_size
            operation.stripped_checksum = self._calculate_checksum(binary_path)
        
        self._save_operations()
        
        print(f"ğŸ“‹ Stripæ“ä½œè®°å½•æ›´æ–°: {operation_id}")
        print(f"   æˆåŠŸ: {success}")
        print(f"   åŠŸèƒ½éªŒè¯: {functionality_verified}")
        
        if success:
            size_reduction = operation.original_size - operation.stripped_size
            reduction_percent = (size_reduction / operation.original_size) * 100
            print(f"   å¤§å°å‡å°‘: {size_reduction:,} bytes ({reduction_percent:.1f}%)")
        
        if error_message:
            print(f"   é”™è¯¯ä¿¡æ¯: {error_message}")
    
    def rollback_operation(self, operation_id: str) -> bool:
        """å›æ»šStripæ“ä½œ"""
        print(f"ğŸ”„ å›æ»šStripæ“ä½œ: {operation_id}")
        
        operation = self._find_operation_by_id(operation_id)
        if not operation:
            print(f"âŒ æ“ä½œä¸å­˜åœ¨: {operation_id}")
            return False
        
        if not operation.backup_path:
            print(f"âŒ æ²¡æœ‰å¤‡ä»½æ–‡ä»¶ï¼Œæ— æ³•å›æ»š")
            return False
        
        backup_path = Path(operation.backup_path)
        binary_path = Path(operation.binary_path)
        
        if not backup_path.exists():
            print(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_path}")
            return False
        
        try:
            # éªŒè¯å¤‡ä»½å®Œæ•´æ€§
            backup_checksum = self._calculate_checksum(backup_path)
            if backup_checksum != operation.original_checksum:
                print(f"âš ï¸  å¤‡ä»½æ–‡ä»¶æ ¡éªŒå’Œä¸åŒ¹é…ï¼Œç»§ç»­å›æ»š...")
            
            # æ‰§è¡Œå›æ»š
            shutil.copy2(backup_path, binary_path)
            
            # éªŒè¯å›æ»šç»“æœ
            restored_checksum = self._calculate_checksum(binary_path)
            if restored_checksum == operation.original_checksum:
                print(f"âœ… å›æ»šæˆåŠŸ: {binary_path}")
                
                # æ›´æ–°æ“ä½œè®°å½•ï¼ˆæ ‡è®°ä¸ºå·²å›æ»šï¼‰
                operation.notes = f"å·²å›æ»šäº {datetime.now().isoformat()}"
                self._save_operations()
                
                return True
            else:
                print(f"âš ï¸  å›æ»šå®Œæˆï¼Œä½†æ ¡éªŒå’Œä¸åŒ¹é…")
                return True
                
        except Exception as e:
            print(f"âŒ å›æ»šå¤±è´¥: {e}")
            return False
    
    def rollback_latest_operation(self) -> bool:
        """å›æ»šæœ€è¿‘çš„Stripæ“ä½œ"""
        if not self.operations:
            print("âŒ æ²¡æœ‰æ“ä½œè®°å½•")
            return False
        
        latest_operation = self.operations[-1]
        return self.rollback_operation(latest_operation.id)
    
    def list_operations(self, limit: int = 10, success_only: bool = False) -> List[StripOperation]:
        """åˆ—å‡ºStripæ“ä½œ"""
        operations = self.operations
        
        if success_only:
            operations = [op for op in operations if op.success]
        
        # æŒ‰æ—¶é—´å€’åºæ’åˆ—
        operations.sort(key=lambda x: x.timestamp, reverse=True)
        
        return operations[:limit]
    
    def list_backups(self, limit: int = 10) -> List[BackupMetadata]:
        """åˆ—å‡ºå¤‡ä»½æ–‡ä»¶"""
        backups = sorted(self.backups, key=lambda x: x.created_at, reverse=True)
        return backups[:limit]
    
    def cleanup_old_backups(self, days_to_keep: int = 30, dry_run: bool = False) -> int:
        """æ¸…ç†æ—§çš„å¤‡ä»½æ–‡ä»¶"""
        print(f"ğŸ§¹ æ¸…ç† {days_to_keep} å¤©å‰çš„å¤‡ä»½æ–‡ä»¶ {'(æ¨¡æ‹Ÿè¿è¡Œ)' if dry_run else ''}")
        
        cutoff_time = datetime.now() - timedelta(days=days_to_keep)
        cleaned_count = 0
        cleaned_size = 0
        
        backups_to_remove = []
        
        for backup in self.backups:
            backup_time = datetime.fromisoformat(backup.created_at)
            
            if backup_time < cutoff_time:
                backup_path = Path(backup.backup_path)
                
                if backup_path.exists():
                    file_size = backup_path.stat().st_size
                    
                    if not dry_run:
                        try:
                            backup_path.unlink()
                            cleaned_count += 1
                            cleaned_size += file_size
                            print(f"   åˆ é™¤: {backup.backup_id} ({file_size:,} bytes)")
                        except Exception as e:
                            print(f"   âš ï¸  åˆ é™¤å¤±è´¥ {backup.backup_id}: {e}")
                    else:
                        cleaned_count += 1
                        cleaned_size += file_size
                        print(f"   å°†åˆ é™¤: {backup.backup_id} ({file_size:,} bytes)")
                
                backups_to_remove.append(backup)
        
        # ä»å…ƒæ•°æ®ä¸­ç§»é™¤
        if not dry_run and backups_to_remove:
            for backup in backups_to_remove:
                self.backups.remove(backup)
            self._save_backups()
        
        print(f"ğŸ§¹ æ¸…ç†å®Œæˆ:")
        print(f"   å¤„ç†æ–‡ä»¶: {cleaned_count}")
        print(f"   é‡Šæ”¾ç©ºé—´: {cleaned_size:,} bytes ({cleaned_size/1024/1024:.1f} MB)")
        
        return cleaned_count
    
    def verify_backup_integrity(self, backup_id: str) -> bool:
        """éªŒè¯å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§"""
        print(f"ğŸ” éªŒè¯å¤‡ä»½å®Œæ•´æ€§: {backup_id}")
        
        backup = self._find_backup_by_id(backup_id)
        if not backup:
            print(f"âŒ å¤‡ä»½ä¸å­˜åœ¨: {backup_id}")
            return False
        
        backup_path = Path(backup.backup_path)
        if not backup_path.exists():
            print(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_path}")
            return False
        
        try:
            current_checksum = self._calculate_checksum(backup_path)
            current_size = backup_path.stat().st_size
            
            checksum_match = current_checksum == backup.checksum
            size_match = current_size == backup.file_size
            
            if checksum_match and size_match:
                print(f"âœ… å¤‡ä»½å®Œæ•´æ€§éªŒè¯é€šè¿‡")
                return True
            else:
                print(f"âŒ å¤‡ä»½å®Œæ•´æ€§éªŒè¯å¤±è´¥:")
                if not checksum_match:
                    print(f"   æ ¡éªŒå’Œä¸åŒ¹é…: æœŸæœ› {backup.checksum[:16]}..., å®é™… {current_checksum[:16]}...")
                if not size_match:
                    print(f"   å¤§å°ä¸åŒ¹é…: æœŸæœ› {backup.file_size:,}, å®é™… {current_size:,}")
                return False
        
        except Exception as e:
            print(f"âŒ å®Œæ•´æ€§éªŒè¯å¤±è´¥: {e}")
            return False
    
    def restore_from_backup(self, backup_id: str, target_path: Optional[Path] = None) -> bool:
        """ä»å¤‡ä»½æ¢å¤æ–‡ä»¶"""
        print(f"ğŸ”„ ä»å¤‡ä»½æ¢å¤: {backup_id}")
        
        backup = self._find_backup_by_id(backup_id)
        if not backup:
            print(f"âŒ å¤‡ä»½ä¸å­˜åœ¨: {backup_id}")
            return False
        
        backup_path = Path(backup.backup_path)
        if not backup_path.exists():
            print(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_path}")
            return False
        
        # ç¡®å®šç›®æ ‡è·¯å¾„
        if target_path is None:
            target_path = Path(backup.original_path)
        
        try:
            # éªŒè¯å¤‡ä»½å®Œæ•´æ€§
            if not self.verify_backup_integrity(backup_id):
                print(f"âš ï¸  å¤‡ä»½å®Œæ•´æ€§éªŒè¯å¤±è´¥ï¼Œä½†ç»§ç»­æ¢å¤...")
            
            # æ‰§è¡Œæ¢å¤
            shutil.copy2(backup_path, target_path)
            
            print(f"âœ… æ¢å¤æˆåŠŸ: {target_path}")
            return True
        
        except Exception as e:
            print(f"âŒ æ¢å¤å¤±è´¥: {e}")
            return False
    
    def _find_operation_by_id(self, operation_id: str) -> Optional[StripOperation]:
        """æ ¹æ®IDæŸ¥æ‰¾æ“ä½œè®°å½•"""
        for operation in self.operations:
            if operation.id == operation_id:
                return operation
        return None
    
    def _find_backup_by_id(self, backup_id: str) -> Optional[BackupMetadata]:
        """æ ¹æ®IDæŸ¥æ‰¾å¤‡ä»½è®°å½•"""
        for backup in self.backups:
            if backup.backup_id == backup_id:
                return backup
        return None
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_operations = len(self.operations)
        successful_operations = len([op for op in self.operations if op.success])
        failed_operations = total_operations - successful_operations
        
        total_backups = len(self.backups)
        total_backup_size = sum(backup.file_size for backup in self.backups)
        
        # è®¡ç®—æ€»èŠ‚çœç©ºé—´
        total_size_saved = sum(
            op.original_size - op.stripped_size 
            for op in self.operations 
            if op.success and op.stripped_size > 0
        )
        
        return {
            'operations': {
                'total': total_operations,
                'successful': successful_operations,
                'failed': failed_operations,
                'success_rate': (successful_operations / total_operations * 100) if total_operations > 0 else 0
            },
            'backups': {
                'total': total_backups,
                'total_size_bytes': total_backup_size,
                'total_size_mb': total_backup_size / (1024 * 1024)
            },
            'compression': {
                'total_size_saved_bytes': total_size_saved,
                'total_size_saved_mb': total_size_saved / (1024 * 1024)
            }
        }
    
    def generate_report(self, output_file: str = "strip_rollback_report.json"):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        print(f"ğŸ“‹ ç”Ÿæˆå›æ»šç®¡ç†æŠ¥å‘Š: {output_file}")
        
        stats = self.get_statistics()
        
        report = {
            'generated_at': datetime.now().isoformat(),
            'statistics': stats,
            'recent_operations': [asdict(op) for op in self.list_operations(20)],
            'recent_backups': [asdict(backup) for backup in self.list_backups(20)],
            'recommendations': self._generate_maintenance_recommendations(stats)
        }
        
        with open(output_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        # ç”Ÿæˆæ‘˜è¦
        summary_file = output_file.replace('.json', '_summary.txt')
        self._generate_summary_report(report, summary_file)
        
        print(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ:")
        print(f"   è¯¦ç»†æŠ¥å‘Š: {output_file}")
        print(f"   æ‘˜è¦æŠ¥å‘Š: {summary_file}")
    
    def _generate_maintenance_recommendations(self, stats: Dict) -> List[str]:
        """ç”Ÿæˆç»´æŠ¤å»ºè®®"""
        recommendations = []
        
        # å¤‡ä»½ç©ºé—´å»ºè®®
        backup_size_mb = stats['backups']['total_size_mb']
        if backup_size_mb > 1000:  # 1GB
            recommendations.append(f"å¤‡ä»½å ç”¨ç©ºé—´è¾ƒå¤§ ({backup_size_mb:.1f} MB)ï¼Œè€ƒè™‘æ¸…ç†æ—§å¤‡ä»½")
        
        # æˆåŠŸç‡å»ºè®®
        success_rate = stats['operations']['success_rate']
        if success_rate < 80:
            recommendations.append(f"StripæˆåŠŸç‡è¾ƒä½ ({success_rate:.1f}%)ï¼Œæ£€æŸ¥Stripç­–ç•¥å’Œç›®æ ‡æ–‡ä»¶å…¼å®¹æ€§")
        
        # ç©ºé—´èŠ‚çœå»ºè®®
        saved_mb = stats['compression']['total_size_saved_mb']
        if saved_mb < 10:
            recommendations.append("Stripå‹ç¼©æ•ˆæœæœ‰é™ï¼Œè¯„ä¼°æ˜¯å¦ç»§ç»­ä½¿ç”¨Strip")
        
        # ç»´æŠ¤å»ºè®®
        total_backups = stats['backups']['total']
        if total_backups > 50:
            recommendations.append("å¤‡ä»½æ–‡ä»¶è¾ƒå¤šï¼Œå®šæœŸæ¸…ç†å¯é‡Šæ”¾å­˜å‚¨ç©ºé—´")
        
        return recommendations
    
    def _generate_summary_report(self, report: dict, output_file: str):
        """ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š"""
        with open(output_file, 'w') as f:
            f.write("ğŸ“‹ Stripå›æ»šç®¡ç†æ‘˜è¦æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = report['statistics']
            f.write("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:\n")
            f.write(f"   Stripæ“ä½œæ€»æ•°: {stats['operations']['total']}\n")
            f.write(f"   æˆåŠŸæ“ä½œ: {stats['operations']['successful']}\n")
            f.write(f"   å¤±è´¥æ“ä½œ: {stats['operations']['failed']}\n")
            f.write(f"   æˆåŠŸç‡: {stats['operations']['success_rate']:.1f}%\n")
            f.write(f"   å¤‡ä»½æ–‡ä»¶æ€»æ•°: {stats['backups']['total']}\n")
            f.write(f"   å¤‡ä»½å ç”¨ç©ºé—´: {stats['backups']['total_size_mb']:.1f} MB\n")
            f.write(f"   æ€»èŠ‚çœç©ºé—´: {stats['compression']['total_size_saved_mb']:.1f} MB\n\n")
            
            # æœ€è¿‘æ“ä½œ
            if report['recent_operations']:
                f.write("ğŸ•’ æœ€è¿‘æ“ä½œ:\n")
                for op in report['recent_operations'][:5]:
                    status = "âœ…" if op['success'] else "âŒ"
                    f.write(f"   {status} {op['id']}: {op['strip_method']} ({op['timestamp'][:10]})\n")
                f.write("\n")
            
            # ç»´æŠ¤å»ºè®®
            if report['recommendations']:
                f.write("ğŸ’¡ ç»´æŠ¤å»ºè®®:\n")
                for rec in report['recommendations']:
                    f.write(f"   â€¢ {rec}\n")
                f.write("\n")
            
            f.write(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {report['generated_at']}\n")


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Stripå›æ»šç®¡ç†å™¨")
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # åˆ›å»ºå¤‡ä»½
    backup_parser = subparsers.add_parser('backup', help='åˆ›å»ºå¤‡ä»½æ–‡ä»¶')
    backup_parser.add_argument('binary', help='äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„')
    
    # å‡†å¤‡Stripæ“ä½œ
    prepare_parser = subparsers.add_parser('prepare', help='å‡†å¤‡Stripæ“ä½œ')
    prepare_parser.add_argument('binary', help='äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„')
    prepare_parser.add_argument('--method', required=True, 
                               choices=['conservative', 'moderate', 'aggressive'],
                               help='Stripæ–¹æ³•')
    prepare_parser.add_argument('--no-backup', action='store_true', help='ä¸åˆ›å»ºå¤‡ä»½')
    
    # å®Œæˆæ“ä½œ
    complete_parser = subparsers.add_parser('complete', help='å®ŒæˆStripæ“ä½œ')
    complete_parser.add_argument('operation_id', help='æ“ä½œID')
    complete_parser.add_argument('--success', action='store_true', help='æ“ä½œæˆåŠŸ')
    complete_parser.add_argument('--verified', action='store_true', help='åŠŸèƒ½å·²éªŒè¯')
    complete_parser.add_argument('--error', help='é”™è¯¯ä¿¡æ¯')
    complete_parser.add_argument('--notes', help='å¤‡æ³¨ä¿¡æ¯')
    
    # å›æ»šæ“ä½œ
    rollback_parser = subparsers.add_parser('rollback', help='å›æ»šStripæ“ä½œ')
    rollback_parser.add_argument('operation_id', nargs='?', help='æ“ä½œID (é»˜è®¤å›æ»šæœ€æ–°æ“ä½œ)')
    
    # åˆ—å‡ºæ“ä½œ
    list_ops_parser = subparsers.add_parser('list-operations', help='åˆ—å‡ºStripæ“ä½œ')
    list_ops_parser.add_argument('--limit', type=int, default=10, help='æ˜¾ç¤ºæ•°é‡é™åˆ¶')
    list_ops_parser.add_argument('--success-only', action='store_true', help='åªæ˜¾ç¤ºæˆåŠŸæ“ä½œ')
    
    # åˆ—å‡ºå¤‡ä»½
    list_backups_parser = subparsers.add_parser('list-backups', help='åˆ—å‡ºå¤‡ä»½æ–‡ä»¶')
    list_backups_parser.add_argument('--limit', type=int, default=10, help='æ˜¾ç¤ºæ•°é‡é™åˆ¶')
    
    # æ¸…ç†å¤‡ä»½
    cleanup_parser = subparsers.add_parser('cleanup', help='æ¸…ç†æ—§å¤‡ä»½')
    cleanup_parser.add_argument('--days', type=int, default=30, help='ä¿ç•™å¤©æ•°')
    cleanup_parser.add_argument('--dry-run', action='store_true', help='æ¨¡æ‹Ÿè¿è¡Œ')
    
    # éªŒè¯å¤‡ä»½
    verify_parser = subparsers.add_parser('verify', help='éªŒè¯å¤‡ä»½å®Œæ•´æ€§')
    verify_parser.add_argument('backup_id', help='å¤‡ä»½ID')
    
    # æ¢å¤å¤‡ä»½
    restore_parser = subparsers.add_parser('restore', help='ä»å¤‡ä»½æ¢å¤')
    restore_parser.add_argument('backup_id', help='å¤‡ä»½ID')
    restore_parser.add_argument('--target', help='ç›®æ ‡è·¯å¾„')
    
    # ç»Ÿè®¡ä¿¡æ¯
    subparsers.add_parser('stats', help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
    
    # ç”ŸæˆæŠ¥å‘Š
    report_parser = subparsers.add_parser('report', help='ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š')
    report_parser.add_argument('-o', '--output', default='strip_rollback_report.json',
                              help='è¾“å‡ºæ–‡ä»¶')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        manager = StripRollbackManager()
        
        if args.command == 'backup':
            binary_path = Path(args.binary)
            backup_id = manager.create_backup(binary_path)
            print(f"âœ… å¤‡ä»½ID: {backup_id}")
        
        elif args.command == 'prepare':
            binary_path = Path(args.binary)
            operation_id = manager.prepare_strip_operation(
                binary_path, 
                args.method, 
                create_backup=not args.no_backup
            )
            print(f"âœ… æ“ä½œID: {operation_id}")
        
        elif args.command == 'complete':
            manager.complete_strip_operation(
                args.operation_id,
                args.success,
                args.verified,
                args.error,
                args.notes
            )
        
        elif args.command == 'rollback':
            if args.operation_id:
                success = manager.rollback_operation(args.operation_id)
            else:
                success = manager.rollback_latest_operation()
            
            if not success:
                sys.exit(1)
        
        elif args.command == 'list-operations':
            operations = manager.list_operations(args.limit, args.success_only)
            if operations:
                print(f"ğŸ“‹ Stripæ“ä½œåˆ—è¡¨ (æœ€è¿‘ {len(operations)} æ¡):")
                for op in operations:
                    status = "âœ…" if op.success else "âŒ"
                    verified = "ğŸ”" if op.functionality_verified else ""
                    print(f"  {status}{verified} {op.id}: {op.strip_method} ({op.timestamp[:16]})")
                    if op.error_message:
                        print(f"       é”™è¯¯: {op.error_message}")
            else:
                print("ğŸ“ æš‚æ— æ“ä½œè®°å½•")
        
        elif args.command == 'list-backups':
            backups = manager.list_backups(args.limit)
            if backups:
                print(f"ğŸ’¾ å¤‡ä»½æ–‡ä»¶åˆ—è¡¨ (æœ€è¿‘ {len(backups)} ä¸ª):")
                for backup in backups:
                    size_mb = backup.file_size / (1024 * 1024)
                    print(f"  ğŸ“¦ {backup.backup_id}: {Path(backup.original_path).name} ({size_mb:.1f} MB)")
                    print(f"       {backup.created_at[:16]} -> {backup.backup_path}")
            else:
                print("ğŸ“ æš‚æ— å¤‡ä»½æ–‡ä»¶")
        
        elif args.command == 'cleanup':
            count = manager.cleanup_old_backups(args.days, args.dry_run)
            if count == 0:
                print("âœ… æ— éœ€æ¸…ç†")
        
        elif args.command == 'verify':
            success = manager.verify_backup_integrity(args.backup_id)
            if not success:
                sys.exit(1)
        
        elif args.command == 'restore':
            target_path = Path(args.target) if args.target else None
            success = manager.restore_from_backup(args.backup_id, target_path)
            if not success:
                sys.exit(1)
        
        elif args.command == 'stats':
            stats = manager.get_statistics()
            print("ğŸ“Š å›æ»šç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   Stripæ“ä½œ: {stats['operations']['total']} æ¬¡ (æˆåŠŸç‡ {stats['operations']['success_rate']:.1f}%)")
            print(f"   å¤‡ä»½æ–‡ä»¶: {stats['backups']['total']} ä¸ª ({stats['backups']['total_size_mb']:.1f} MB)")
            print(f"   èŠ‚çœç©ºé—´: {stats['compression']['total_size_saved_mb']:.1f} MB")
        
        elif args.command == 'report':
            manager.generate_report(args.output)
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()